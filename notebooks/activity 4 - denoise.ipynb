{"cells":[{"cell_type":"markdown","source":["**Professor:** Enrique Garcia Ceja\n","**email:** enrique.gc@tec.mx"],"metadata":{"id":"JaseZsy-5WAa"}},{"cell_type":"markdown","metadata":{"id":"yQ7-rVrE5Vk7"},"source":["# Exercise: Removing masks from profile pictures using a convolutional autoenconder.\n","\n","In this exercise you will build an autoencoder to perform a denoising operation. Specifically, removing mask filters from pictures.\n","\n","<img src=\"https://github.com/enriquegit/ap-img/blob/main/img/unmask.png?raw=true\" width=\"600\">\n","\n","For this task, you will use a dataset from Tinder profile pictures. A python script was used to apply a dog filter to the pictures. In a previous work, the authors used Generative Adversarial Networks (GANs) to denoise the pictures. [Here](https://github.com/ipsingh06/ml-desnapify) you can find the original code to apply the filters and solve the problem using GANs.\n","\n","Now, you will explore if it is possible to remove those annoying filters using an autoencoder! Based on training data, the autoencoder will try to 'imagine' what is under the mask and it will try to recreate the original face without filters.\n"]},{"cell_type":"markdown","source":["### Instructions to upload dataset\n","\n","**Note: Before uploading the dataset make sure you have selected the GPU runtime!**\n","\n","1. Create a folder named \"datasets\" in the current working directory (same level as the \"sample_data\" directory).\n","\n","2. Upload the *sample_faces.zip* (provided by the professor) file in the newely created \"datasets\" directory. It may take some minutes.\n","\n","3. Run the following cell to unzip the files."],"metadata":{"id":"f30QxZnm8fPg"}},{"cell_type":"code","source":["# This cell is used to unzip the faces dataset.\n","import zipfile\n","\n","with zipfile.ZipFile(\"datasets/sample_faces.zip\", 'r') as zip_ref:\n","    zip_ref.extractall(\"datasets/\")"],"metadata":{"id":"6NJnl5ca82WV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQkYXGZ55Vk8"},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.preprocessing import image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d38gvKAU5Vk8"},"outputs":[],"source":["# Specify the parent path where the the 'masked' and 'original' pictures are.\n","\n","rootpath = \"datasets/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4SGrZ9lH5Vk9"},"outputs":[],"source":["files_original = os.listdir(rootpath + \"original/\")\n","\n","files_mask = os.listdir(rootpath + \"masked/\")\n","\n","n = 2500 # Number of images to process.\n","\n","target_size = (200,200) # Image size. For computational reasons, resize the images to 200x200\n","\n","imgs_original = [] # Original images are stored here.\n","\n","imgs_mask = [] # Images with mask are stored here.\n","\n","for i in range(n):\n","    img = image.load_img(rootpath + \"original/\" + files_original[i], target_size=target_size)\n","    img = image.img_to_array(img)\n","    img = img/255.\n","    imgs_original.append(img)\n","\n","    img2 = image.load_img(rootpath + \"masked/\" + files_mask[i], target_size=target_size)\n","    img2 = image.img_to_array(img2)\n","    img2 = img2/255.\n","    imgs_mask.append(img2)\n","\n","imgs_original=np.array(imgs_original)\n","\n","imgs_mask=np.array(imgs_mask)\n","\n","# shuffle images\n","n = imgs_original.shape[0]\n","np.random.seed(123)\n","idxs = np.random.choice(n, size=n, replace=False)\n","imgs_original = imgs_original[idxs,:,:,:]\n","imgs_mask = imgs_mask[idxs,:,:,:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8qLSDTIV5Vk9"},"outputs":[],"source":["selected = 55 # Select an image to display.\n","\n","plt.imshow(imgs_original[selected,])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h2l_PXrE5Vk9"},"outputs":[],"source":["# Display same image but with filter applied.\n","\n","plt.imshow(imgs_mask[selected,])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"an8LfKgZ5Vk9"},"outputs":[],"source":["# Select some test images.\n","\n","n_test = 100 # number of images to use as test set\n","\n","# This is the training set.\n","train_orig = imgs_original[n_test:,:,:,:]\n","train_mask = imgs_mask[n_test:,:,:,:]\n","\n","# This is the test set.\n","test_orig = imgs_original[0:n_test,:,:,:]\n","test_mask = imgs_mask[0:n_test,:,:,:]"]},{"cell_type":"markdown","metadata":{"id":"MXwxmXUv5Vk9"},"source":["`train_orig` and `train_mask` contain the train set images with and without masks.\n","\n","`test_orig` and `test_mask` contain the test set images with and without masks.\n","\n","\n","### Now, it is time to define the convolutional autoencoder. Since the purpose of this model is not to compress data but to denoise, it is not necessary for the 'middle layer' to be very small."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yjgSUUcd5Vk9"},"outputs":[],"source":["# Define your convolutional autoencoder and name it 'autoencoder'.\n","# YOUR CODE HERE.\n","\n","\n","\n","\n","\n","\n","\n","# This time we will use the Adam optimizer instead of SGD\n","# which uses momentum.\n","opt = optimizers.Adam()\n","\n","# Compile the model.\n","autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n","\n","# Print a summary of the model.\n","print(autoencoder.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"a2BRS4Ub5Vk9"},"outputs":[],"source":["# Train the autoencoder with the fit function. The inputs are the images with mask and the predicted images\n","# are the ones without masks.\n","# YOUR CODE HERE.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jfFCfu85Vk-"},"outputs":[],"source":["# Let's display the masked images (first n) and the predicted denoised images (bottom).\n","\n","# Number of images to display from training set\n","n = 10\n","\n","decoded_imgs = autoencoder.predict(train_mask[1:n+1,])\n","\n","plt.figure(figsize=(20, 4))\n","for i in range(n):\n","    # display original\n","    ax = plt.subplot(2, n, i + 1)\n","    plt.imshow(train_mask[i+1].reshape(train_orig.shape[1], train_orig.shape[2], train_orig.shape[3]))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","\n","    # display reconstruction\n","    ax = plt.subplot(2, n, i + 1 + n)\n","    plt.imshow(decoded_imgs[i].reshape(train_orig.shape[1], train_orig.shape[2], train_orig.shape[3]))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jTIF-1YW5Vk-"},"outputs":[],"source":["# Now lets try the autoencoder on the test set!\n","\n","startpos = 0 # start position. Try different start positions: 10, 20, 30, etc.\n","\n","n = 10 # # number of images to show begining at startpos.\n","\n","decoded_imgs = autoencoder.predict(test_mask[startpos:startpos+n,])\n","\n","plt.figure(figsize=(20, 4))\n","for i in range(n):\n","    # display original\n","    ax = plt.subplot(2, n, i + 1)\n","    plt.imshow(test_mask[i+startpos].reshape(test_orig.shape[1], test_orig.shape[2], test_orig.shape[3]))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","\n","    # display reconstruction\n","    ax = plt.subplot(2, n, i + 1 + n)\n","    plt.imshow(decoded_imgs[i].reshape(test_orig.shape[1], test_orig.shape[2], test_orig.shape[3]))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}